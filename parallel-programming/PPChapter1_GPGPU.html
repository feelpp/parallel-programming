<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>GPGPU (General-Purpose Graphics Processing Unit) :: Parallel Programming</title>
    <link rel="canonical" href="https://feelpp.github.io/parallel-programming/parallel-programming/PPChapter1_GPGPU.html">
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../_/css/site.css">
<link rel="icon" href="../_/img/favicon.ico" type="image/x-icon">
<script>!function(l,p){if(l.protocol!==p&&l.host=="docs.antora.org"){l.protocol=p}else if(/\.gitlab\.io$/.test(l.host)){l.replace(p+"//docs.antora.org"+l.pathname.substr(l.pathname.indexOf("/",1))+l.search+l.hash)}}(location,"https:")</script>

<script src="../_/js/vendor/tabs-block-extension.js"></script>
<script src="../_/js/vendor/tabs-block-behavior.js"></script>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\\[','\\]']],
    processEscapes: true,
    processEnvironments: true,
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },

  TeX: {
      Macros: {
      bold: ["{\\bf #1}",1],
      calTh: "{\\mathcal{T}_h}",
      card: ["{\\operatorname{card}(#1)}",1],
      card: ["{\\operatorname{card}(#1)}",1],
      Ck: ["{\\mathcal{C}^{#1}}",1],
      deformt: ["{\\mathbf{\\varepsilon(#1)}}",1],
      diam: "{\\operatorname{diam}}",
      dim: ["{\\operatorname{dim}(#1)}",1],
      disp: ["{\\mathbf{#1}}",1],
      domain: "{\\Omega}",
      ds: "",
      essinf: "{\\operatorname{ess}\\, \\operatorname{inf}}",
      F:"{\\mathcal{F}}",
      geo: "{\\mathrm{geo}}",
      Ich: ["{\\mathcal{I}^{#1}_{c,h}#2}",2],
      Id: "{\\mathcal{I}}",
      Ilag: ["{\\mathcal{I}^{\\mathrm{lag}}_{#1}}",1],
      jump: ["{[\\![ #1 ]\\!]}",1],
      n:"{\\mathbf{n}}",
      Ne: "{N_{\\mathrm{e}}}",
      Next: "{\\mathrm{n}}",
      nf: "{n_f}",
      ngeo: "{n_{\\mathrm{geo}}}",
      Nma: "{N_{\\mathrm{ma}}}",
      NN: "{\\mathbb N}",
      Nno: "{N_{\\mathrm{no}}}",
      Nso: "{N_{\\mathrm{so}}}",
      opdim: "{\\operatorname{dim}}",
      p: "{\\mathrm{p}}",
      P:"{\\mathcal{P}}",
      Pch: ["{P^{#1}_{c,h}}",1],
      Pcho: ["{P^{#1}_{c,h,0}}",1],
      Pk: ["{\\mathcal{P}^{#1}}",1],
      poly: ["{\\mathbb{#1}",1],
      poly: ["{\\mathbb{#1}}",1],
      prect: ["{\\left\\(#1\\right\\)}",1],
      q:"{\\mathbf{q}}",
      Qch: ["{Q^{#1}_{c,h}}",1],
      Qk: ["{\\mathcal{Q}^{#1}}",1],
      R: ["{\\mathbb{R}^{#1}}",1],
      RR: "{\\mathbb R}",
      set: ["{\\left\\{#1\\right\\}}",1],
      stresst: ["{\\mathbf{\\sigma(#1)}}",1],
      T:"{\\mathcal{T}}",
      tr: "{\\operatorname{tr}}",
      v:"{\\mathbf{v}}",
      vertiii: ["\\left\\vert\\kern-0.25ex\\left\\vert\\kern-0.25ex\\left\\vert #1 \\right\\vert\\kern-0.25ex\\right\\vert\\kern-0.25ex\\right\\vert",1]
  },
  extensions: ["mhchem.js"] 
  }
});
</script>
<!--<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/MathJax.js?config=TeX-MML-AM_CHTML"></script>-->
<!-- <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML' async></script> -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_CHTML'></script>
<!--<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.6.0/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>-->

<!--<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css" integrity="sha384-TEMocfGvRuD1rIAacqrknm5BQZ7W7uWitoih+jMNFXQIbNl16bO8OZmylH/Vi/Ei" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js" integrity="sha384-jmxIlussZWB7qCuB+PgKG1uLjjxbVVIayPJwi6cG6Zb4YKq0JIw+OMnkkEC7kYCq" crossorigin="anonymous"></script>-->
<script>var uiRootPath = '../_'</script>

  </head>
  <body class="article">
<header class="header">
    <nav class="navbar navbar-expand-sm bg-dark navbar-dark navbar-template-project" style="border-top: 4px solid #9E9E9E">
        <div class="navbar-brand">
            <div class="navbar-item feelpp-logo">
                <a href="https://feelpp.github.io/parallel-programming">Parallel Programming</a>
            </div>
            <button class="navbar-burger" data-target="topbar-nav">
                <span></span>
                <span></span>
                <span></span>
            </button>
        </div>

        <div id="topbar-nav" class="navbar-menu">
            <div class="navbar-end">
                <div class="navbar-item">
                    <a href="https://docs.feelpp.org/">Documentation Reference</a>
                </div>
                <div class="navbar-item has-dropdown is-hoverable download-item">
                    <div class="navbar-item"><a href="https://docs.feelpp.org/user/latest/install/index.html" class="download-btn">Get Feel++</a></div>
                </div>
                <div class="navbar-item">
                    <a class="navbar-brand"  href="https://www.cemosis.fr">
                        <img class="cemosis-logo"  src="../_/img/cemosis-logo.svg" alt="Cemosis logo"/>
                    </a>
                </div>
            </div>
        </div>
    </nav>
</header>
<div class="body">
<a href="#" class="menu-expand-toggle"></a>
<div class="nav-container" data-component="parallel-programming" data-version="">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="index.html">Main</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="index.html">Introduction</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter1_CPU.html">CPU Architecture</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter1_GPU.html">GPU Architecture</a>
  </li>
  <li class="nav-item is-current-page" data-depth="1">
    <a class="nav-link" href="PPChapter1_GPGPU.html">GPGPU Architecture</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter1_TPU.html">TPU Architecture</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter1_SIMD.html">SIMD Architecture</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter2_MPI.html">MPI (Message Passing Interface)</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter2_OpenMP.html">OpenMP (Open Multi-Processing)</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter2_Hybrid.html">Hybrid MPI with OpenMP</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter3.html">StarPU</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter4.html">Specx</a>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Main</span>
    <span class="version"></span>
  </div>
  <ul class="components">
      <li class="component">
        <a class="title" href="../feelpp-antora-ui/index.html">Antora Feel++ UI</a>
      </li>
      <li class="component is-current">
        <a class="title" href="index.html">Main</a>
      </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
  <button class="nav-toggle"></button>
    <a href="index.html" class="home-link"></a>
  <nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="index.html">Main</a></li>
    <li><a href="PPChapter1_GPGPU.html">GPGPU Architecture</a></li>
  </ul>
</nav>

  
    <div class="edit-this-page"><a href="https://github.com/feelpp/parallel-programming/edit/lem/docs/modules/ROOT/pages/PPChapter1_GPGPU.adoc">Edit this Page</a></div>
  
  <div class="page-downloads">
  <span class="label">Download as</span>
  <ul class="download-options">
    <li>
      <a onclick="print(this)" href="#" data-toggle="tooltip" data-placement="left" title="Print to PDF"
         class="pdf-download">
        <img class="pdf-file-icon icon" src="../_/img/pdf.svg"/> .pdf
      </a>
    </li>
  </ul>
</div>
</div>

  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">GPGPU (General-Purpose Graphics Processing Unit)</h1>
<div class="paragraph">
<p><span class="image"><a class="image" href="#fragment4"><img src="_images/image4.png" alt="image4" width="642" height="331"></a></span></p>
</div>
<div class="paragraph">
<p>A <strong>General-Purpose Graphics Processing Unit</strong> (GPGPU) is a graphics
processing unit (GPU) that is programmed for purposes beyond graphics
processing, such as performing computations typically conducted by a
Central Processing Unit (CPU).</p>
</div>
<div class="paragraph">
<p><em>GPGPU</em> is short for general-purpose computing on graphics processing
units. Graphics processors or GPUs today are capable of much more than
calculating pixels in video games. For this, Nvidia has been developing
for four years a hardware interface and a programming language derived
from C, CUDA ( <strong>C</strong> ompute <strong>Unified Device Architecture</strong> ). This
technology, known as <strong>GPGPU</strong> ( <strong>General</strong> - <strong>P</strong> urpose computation on <strong>G</strong>
raphic <strong>P</strong> rocessing <strong>Units</strong> ) exploits the computing power of GPUs for
the processing of massively parallel tasks. Unlike the CPU, a GPU is not
suited for fast processing of tasks that run sequentially. On the other
hand, it is very suitable for processing parallelizable algorithms.</p>
</div>
<div class="paragraph">
<p>•Array of independent "cores" called calculation units</p>
</div>
<div class="ulist">
<ul>
<li>
<p>High bandwidth, banked L2 caches and main memory</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>− Banks allow several parallel accesses</p>
</div>
<div class="paragraph">
<p>− 100s of GB/s</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Memory and caches are generally inconsistent</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Compute units are based on SIMD hardware</p>
</div>
<div class="paragraph">
<p>− Both AMD and NVIDIA have 16-element wide SIMDs</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Large registry files are used for fast context switching</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>− No save/restore state</p>
</div>
<div class="paragraph">
<p>− Data is persistent throughout the execution of the thread</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Both providers have a combination of automatic L1 cache and
user-managed scratchpad</p>
</li>
<li>
<p>Scratchpad is heavily loaded and has very high bandwidth
(~terabytes/second)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Work items are automatically grouped into hardware threads called
"wavefronts" (AMD) or "warps" (NVIDIA)</p>
</div>
<div class="paragraph">
<p>− Single instruction stream executed on SIMD hardware</p>
</div>
<div class="paragraph">
<p>− 64 work items in a wavefront, 32 in a string</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The instruction is issued multiple times on the 16-channel SIMD unit</p>
</li>
<li>
<p>Control flow is managed by masking the SIMD channel</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>NVIDIA coined "Single Instruction Multiple Threads" (SIMT) to refer to
multiple (software) threads sharing a stream of instructions</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Work items run in sequence on SIMD hardware</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>− Multiple software threads are executed on a single hardware thread</p>
</div>
<div class="paragraph">
<p>− Divergence between managed threads using predication</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Accuracy is transparent to the OpenCL model</p>
</li>
<li>
<p>Performance is highly dependent on understanding work items to SIMD
mapping</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Architecture of a GPU versus CPU</strong></p>
</div>
<div class="paragraph">
<p>Such an architecture is said to be "throughput-oriented". The latest
from the Santa-Clara firm, codenamed “Fermi” has 512 cores.</p>
</div>
<div class="paragraph">
<p><span class="image"><a class="image" href="#fragment5"><img src="_images/image5.png" alt="image5" width="530" height="241"></a></span></p>
</div>
<div class="paragraph">
<p><em>CPU architecture vs. GPUs</em></p>
</div>
<div class="paragraph">
<p>Traditional microprocessors (CPUs) are essentially "low latency
oriented". The goal is to minimize the execution time of a single
sequence of a program by reducing latency as much as possible. This
design takes the traditional assumption that parallelism in the
operations that the processor must perform is very rare.</p>
</div>
<div class="paragraph">
<p>Throughput-oriented processors assume that their workload requires
significant parallelism. The idea is not to execute the operations as
quickly as possible sequentially, but to execute billions of operations
simultaneously in a given time, the execution time of one of these
operations is ultimately almost irrelevant. In a video game, for
example, performance is measured in FPS (Frames Per Seconds). To do
this, an image, with all the pixels, must be displayed every 30
milliseconds (approximately). It doesn&#8217;t matter how long a single pixel
is displayed.</p>
</div>
<div class="paragraph">
<p>This type of processor has small independent calculation units which
execute the instructions in the order in which they appear in the
program, there is ultimately little dynamic control over the execution.
Thea term <strong>SIMD</strong> is used for these processors (<strong>S</strong>ingle <strong>I</strong>nstruction <strong>M</strong>ultiple <strong>Da</strong>ta).</p>
</div>
<div class="paragraph">
<p>Each PU (Processing Unit) does not necessarily correspond to a
processor, they are calculation units. In this mode, the same
instruction is applied simultaneously to several data.</p>
</div>
<div class="paragraph">
<p>Less control logic means more space on the chip dedicated to the
calculation. However, this also comes at a cost. A SIMD execution gets a
performance peak when parallel tasks follow the same branch of
execution, which deteriorates when the tasks branch off. Indeed, the
calculation units assigned to a branch will have to wait for the
execution of the calculation units of the previous branch. This results
in hardware underutilization and increased execution time. The
efficiency of the SIMD architecture depends on the uniformity of the
workload.</p>
</div>
<div class="paragraph">
<p>However, due to the large number of computational units, it may not be
very important to have some threads blocked if others can continue their
execution. Long-latency operations performed on one thread are "hidden"
by others ready to execute another set of instructions.</p>
</div>
<div class="paragraph">
<p>For a quad or octo-core CPU, the creation of threads and their
scheduling has a cost. For a GPU, the relative latency "covers" these 2
steps, making them negligible. However, memory transfers have greater
implications for a GPU than a CPU because of the need to move data
between CPU memory and GPU memory.</p>
</div>
<div class="paragraph">
<p>(See:
<a href="https://blog.octo.com/la-technologie-gpgpu-1ere-partie-le-cote-obscur-de-la-geforce/" class="bare">blog.octo.com/la-technologie-gpgpu-1ere-partie-le-cote-obscur-de-la-geforce/</a>
)</p>
</div>
</article>
  </div>
</main>
</div>
<footer class="footer" style="border-top: 2px solid #e9e9e9; background-color: #fafafa; padding-bottom: 2em; padding-top: 2em;">
    <div class="container" style="display: flex; flex-direction: column; align-items: center; gap: 0.5em;">
        <div>
            <a href="https://www.cemosis.fr">
                <img src="../_/img/cemosis-logo.svg" alt="Cemosis logo" height="50">
            </a>
        </div>
        <span style="font-size: 0.8rem; color: #9e9e9e">© 2023 <a href="https://www.cemosis.fr" style="text-decoration: underline;">Cemosis</a>, Université de Strasbourg</span>
    </div>
</footer>
<script id="site-script" src="../_/js/site.js" data-ui-root-path="../_"></script>


<script async src="../_/js/vendor/fontawesome-icon-defs.js"></script>
<script async src="../_/js/vendor/fontawesome.js"></script>
<script async src="../_/js/vendor/highlight.js"></script>


<script type="text/javascript">
function toggleFullScreen() {
   var doc = window.document;
   var docEl = doc.documentElement;

   var requestFullScreen = docEl.requestFullscreen || docEl.mozRequestFullScreen || docEl.webkitRequestFullScreen || docEl.msRequestFullscreen;
   var cancelFullScreen = doc.exitFullscreen || doc.mozCancelFullScreen || doc.webkitExitFullscreen || doc.msExitFullscreen;

   if(!doc.fullscreenElement && !doc.mozFullScreenElement && !doc.webkitFullscreenElement && !doc.msFullscreenElement) {
       requestFullScreen.call(docEl);
   }
   else {
       cancelFullScreen.call(doc);
   }
}
</script>
  </body>
</html>
