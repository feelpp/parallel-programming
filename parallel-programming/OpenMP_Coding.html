<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>OpenMP Coding Practice :: Parallel Programming</title>
    <link rel="canonical" href="https://feelpp.github.io/parallel-programming/parallel-programming/OpenMP_Coding.html">
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../_/css/site.css">
<link rel="icon" href="../_/img/favicon.ico" type="image/x-icon">
<script>!function(l,p){if(l.protocol!==p&&l.host=="docs.antora.org"){l.protocol=p}else if(/\.gitlab\.io$/.test(l.host)){l.replace(p+"//docs.antora.org"+l.pathname.substr(l.pathname.indexOf("/",1))+l.search+l.hash)}}(location,"https:")</script>

<script src="../_/js/vendor/tabs-block-extension.js"></script>
<script src="../_/js/vendor/tabs-block-behavior.js"></script>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\\[','\\]']],
    processEscapes: true,
    processEnvironments: true,
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },

  TeX: {
      Macros: {
      bold: ["{\\bf #1}",1],
      calTh: "{\\mathcal{T}_h}",
      card: ["{\\operatorname{card}(#1)}",1],
      card: ["{\\operatorname{card}(#1)}",1],
      Ck: ["{\\mathcal{C}^{#1}}",1],
      deformt: ["{\\mathbf{\\varepsilon(#1)}}",1],
      diam: "{\\operatorname{diam}}",
      dim: ["{\\operatorname{dim}(#1)}",1],
      disp: ["{\\mathbf{#1}}",1],
      domain: "{\\Omega}",
      ds: "",
      essinf: "{\\operatorname{ess}\\, \\operatorname{inf}}",
      F:"{\\mathcal{F}}",
      geo: "{\\mathrm{geo}}",
      Ich: ["{\\mathcal{I}^{#1}_{c,h}#2}",2],
      Id: "{\\mathcal{I}}",
      Ilag: ["{\\mathcal{I}^{\\mathrm{lag}}_{#1}}",1],
      jump: ["{[\\![ #1 ]\\!]}",1],
      n:"{\\mathbf{n}}",
      Ne: "{N_{\\mathrm{e}}}",
      Next: "{\\mathrm{n}}",
      nf: "{n_f}",
      ngeo: "{n_{\\mathrm{geo}}}",
      Nma: "{N_{\\mathrm{ma}}}",
      NN: "{\\mathbb N}",
      Nno: "{N_{\\mathrm{no}}}",
      Nso: "{N_{\\mathrm{so}}}",
      opdim: "{\\operatorname{dim}}",
      p: "{\\mathrm{p}}",
      P:"{\\mathcal{P}}",
      Pch: ["{P^{#1}_{c,h}}",1],
      Pcho: ["{P^{#1}_{c,h,0}}",1],
      Pk: ["{\\mathcal{P}^{#1}}",1],
      poly: ["{\\mathbb{#1}",1],
      poly: ["{\\mathbb{#1}}",1],
      prect: ["{\\left\\(#1\\right\\)}",1],
      q:"{\\mathbf{q}}",
      Qch: ["{Q^{#1}_{c,h}}",1],
      Qk: ["{\\mathcal{Q}^{#1}}",1],
      R: ["{\\mathbb{R}^{#1}}",1],
      RR: "{\\mathbb R}",
      set: ["{\\left\\{#1\\right\\}}",1],
      stresst: ["{\\mathbf{\\sigma(#1)}}",1],
      T:"{\\mathcal{T}}",
      tr: "{\\operatorname{tr}}",
      v:"{\\mathbf{v}}",
      vertiii: ["\\left\\vert\\kern-0.25ex\\left\\vert\\kern-0.25ex\\left\\vert #1 \\right\\vert\\kern-0.25ex\\right\\vert\\kern-0.25ex\\right\\vert",1]
  },
  extensions: ["mhchem.js"] 
  }
});
</script>
<!--<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/MathJax.js?config=TeX-MML-AM_CHTML"></script>-->
<!-- <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML' async></script> -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_CHTML'></script>
<!--<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.6.0/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>-->

<!--<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css" integrity="sha384-TEMocfGvRuD1rIAacqrknm5BQZ7W7uWitoih+jMNFXQIbNl16bO8OZmylH/Vi/Ei" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js" integrity="sha384-jmxIlussZWB7qCuB+PgKG1uLjjxbVVIayPJwi6cG6Zb4YKq0JIw+OMnkkEC7kYCq" crossorigin="anonymous"></script>-->
<script>var uiRootPath = '../_'</script>

  </head>
  <body class="article">
<header class="header">
    <nav class="navbar navbar-expand-sm bg-dark navbar-dark navbar-template-project" style="border-top: 4px solid #9E9E9E">
        <div class="navbar-brand">
            <div class="navbar-item feelpp-logo">
                <a href="https://feelpp.github.io/parallel-programming">Parallel Programming</a>
            </div>
            <button class="navbar-burger" data-target="topbar-nav">
                <span></span>
                <span></span>
                <span></span>
            </button>
        </div>

        <div id="topbar-nav" class="navbar-menu">
            <div class="navbar-end">
                <div class="navbar-item">
                    <a href="https://docs.feelpp.org/">Documentation Reference</a>
                </div>
                <div class="navbar-item has-dropdown is-hoverable download-item">
                    <div class="navbar-item"><a href="https://docs.feelpp.org/user/latest/install/index.html" class="download-btn">Get Feel++</a></div>
                </div>
                <div class="navbar-item">
                    <a class="navbar-brand"  href="https://www.cemosis.fr">
                        <img class="cemosis-logo"  src="../_/img/cemosis-logo.svg" alt="Cemosis logo"/>
                    </a>
                </div>
            </div>
        </div>
    </nav>
</header>
<div class="body">
<a href="#" class="menu-expand-toggle"></a>
<div class="nav-container" data-component="parallel-programming" data-version="">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="index.html">Main</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="index.html">Introduction</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter1_CPU.html">CPU Architecture</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter1_GPU.html">GPU Architecture</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter1_GPGPU.html">GPGPU Architecture</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter1_TPU.html">TPU Architecture</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter1_SIMD.html">SIMD Architecture</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter2_MPI.html">MPI (Message Passing Interface)</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter2_OpenMP.html">OpenMP (Open Multi-Processing)</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter2_Hybrid.html">Hybrid MPI with OpenMP</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter3.html">StarPU</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter4.html">Specx</a>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Main</span>
    <span class="version"></span>
  </div>
  <ul class="components">
      <li class="component">
        <a class="title" href="../feelpp-antora-ui/index.html">Antora Feel++ UI</a>
      </li>
      <li class="component is-current">
        <a class="title" href="index.html">Main</a>
      </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
  <button class="nav-toggle"></button>
    <a href="index.html" class="home-link"></a>
  <nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="index.html">Main</a></li>
    <li><a href="OpenMP_Coding.html">OpenMP Coding Practice</a></li>
  </ul>
</nav>

  
    <div class="edit-this-page"><a href="https://github.com/feelpp/parallel-programming/edit/lem/docs/modules/ROOT/pages/OpenMP_Coding.adoc">Edit this Page</a></div>
  
  <div class="page-downloads">
  <span class="label">Download as</span>
  <ul class="download-options">
    <li>
      <a onclick="print(this)" href="#" data-toggle="tooltip" data-placement="left" title="Print to PDF"
         class="pdf-download">
        <img class="pdf-file-icon icon" src="../_/img/pdf.svg"/> .pdf
      </a>
    </li>
  </ul>
</div>
</div>

  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">OpenMP Coding Practice</h1>
<div class="ulist">
<ul>
<li>
<p>Compiling a program for OpenMP is almost just like compiling a regular C or C++ program. For example, to compile MyProg.c you would use a command like:</p>
<div class="ulist">
<ul>
<li>
<p>gcc -fopenmp -o MyProg MyProg.c</p>
</li>
<li>
<p>gcc -fopenmp -o MyProg MyProg.cpp</p>
</li>
<li>
<p>g++ -c MyProg. cpp -o MyProg.o -fopenmp</p>
</li>
<li>
<p>g++ MyProg.o -o MyProg -fopenmp -lpthread</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="sidebarblock examp">
<div class="content">
<div class="title">Start</div>
<div class="paragraph">
<p>This start example illustrates how to do a task reduction and consists in calculating the sum of all elements of an array.</p>
</div>
<div class="listingblock">
<div class="title">Code Start</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-cpp hljs" data-lang="cpp">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;omp.h&gt;

/**
 * @brief Illustrates how to do a task reduction.
 * @details This example consists in calculating the sum of all elements of an
 * array.
 **/
int main(int argc, char* argv[])
{
	// Use 4 OpenMP threads
	omp_set_num_threads(4);

	// Variable that will be private
	int val = 123456789;

	printf("Value of \"val\" before the OpenMP parallel region: %d.\n", val);

	#pragma omp parallel private(val)
	{
		printf("Thread %d sees \"val\" = %d, and updates it to be %d.\n", omp_get_thread_num(), val, omp_get_thread_num());
		val = omp_get_thread_num();
	}

	// Value after the parallel region; unchanged.
	printf("Value of \"val\" after the OpenMP parallel region: %d.\n", val);


	return 0;
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sidebarblock examp">
<div class="content">
<div class="title">Firstprivate</div>
<div class="paragraph">
<p>Specifies that each thread should have its own instance of a variable, and that the variable should be initialized with the value of the variable, because it exists before the parallel construct.
.Code Firstprivate</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-cpp hljs" data-lang="cpp">#include &lt;omp.h&gt;
#include &lt;stdio.h&gt;

// not using iostream here due to output ordering issues

// iostream tends to output each part between &lt;&lt;'s separately to the console, 
// which can lead to random output if multiple threads are doing the same
// thing.

// printf will generally output the whole result string in one go, so results
// of separate printf calls, even from different threads, will remain intact

// Another fix, other than using printf, would be to give each thread its own 
// place to store output temporarily (a stringstream), and then output the whole
// result in one go.

int main() {
	
	omp_set_num_threads(4);

	// Variable that will be firstprivate
	int val = 123456789;

	printf("Value of \"val\" before the OpenMP parallel region: %d.\n", val);

	#pragma omp parallel firstprivate(val)
	{
		printf("Thread %d sees \"val\" = %d, and updates it to be %d.\n", omp_get_thread_num(), val, omp_get_thread_num());
		val = omp_get_thread_num();
	}

	// Value after the parallel region; unchanged.
	printf("Value of \"val\" after the OpenMP parallel region: %d.\n", val);

	return 0;
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sidebarblock examp">
<div class="content">
<div class="title">Private</div>
<div class="paragraph">
<p>The private clause declares the variables in the list to be private to each thread in a team.
.Code Private</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-cpp hljs" data-lang="cpp">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;omp.h&gt;

/**
 * @brief Illustrates the OpenMP private policy.
 * @details This example shows that when a private variable is passed to a
 * parallel region, threads work on uninitialised copies and that whatever
 * modification is made to their copies is not reflected onto the original
 * variable. 
 **/
int main(int argc, char* argv[])
{
	// Use 4 OpenMP threads
	omp_set_num_threads(4);

	// Variable that will be private
	int val = 123456789;

	printf("Value of \"val\" before the OpenMP parallel region: %d.\n", val);

	#pragma omp parallel private(val)
	{
		printf("Thread %d sees \"val\" = %d, and updates it to be %d.\n", omp_get_thread_num(), val, omp_get_thread_num());
		val = omp_get_thread_num();
	}

	// Value after the parallel region; unchanged.
	printf("Value of \"val\" after the OpenMP parallel region: %d.\n", val);

	return EXIT_SUCCESS;
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sidebarblock examp">
<div class="content">
<div class="title">Lastprivate</div>
<div class="paragraph">
<p>Specifies that the enclosing context&#8217;s version of the variable is set equal to the private version of whichever thread executes the final iteration (for-loop construct) or last section (#pragma sections).</p>
</div>
<div class="listingblock">
<div class="title">Code Lastprivate</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-cpp hljs" data-lang="cpp">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;omp.h&gt;

/**
 * @brief Illustrates the OpenMP lastprivate policy.
 * @details This example shows that when a lastprivate variable is passed to a
 * parallelised for loop, threads work on uninitialised copies but, at the end
 * of the parallelised for loop, the thread in charge of the last iteration
 * sets the value of the original variable to that of its own copy.
 **/
int main(int argc, char* argv[])
{
	// Use 4 OpenMP threads
	omp_set_num_threads(4);

	// Variable that will be lastprivate
	int val = 123456789;

	printf("Value of \"val\" before the OpenMP parallel region: %d.\n", val);

	#pragma omp parallel for lastprivate(val)
	for(int i = 0; i &lt; omp_get_num_threads(); i++)
	{
		val = omp_get_thread_num();
	}

	// Value after the parallel region; unchanged.
	printf("Value of \"val\" after the OpenMP parallel region: %d. Thread %d was therefore the last one to modify it.\n", val, val);

	return 0;
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sidebarblock examp">
<div class="content">
<div class="title">Linear</div>
<div class="paragraph">
<p>The linear clause provides a superset of the functionality provided by the private clause.</p>
</div>
<div class="listingblock">
<div class="title">Code Linear</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-cpp hljs" data-lang="cpp">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;omp.h&gt;

/**
 * @brief Illustrates the OpenMP linear policy.
 * @details This example shows that when a linear variable is passed to a
 * parallelised for loop, the value of that variable is the original value plus 
 * the iteration logical number times the linear-step. After the OpenMP parallel
 * for, the value of the original variable is that of the linear variable at the
 * last iteration.
 **/
int main(int argc, char* argv[])
{
	// Use 4 OpenMP threads
	omp_set_num_threads(4);

	// Variable that will be private
	int val = 1;

	printf("Value of \"val\" before the OpenMP parallel for is %d.\n", val);

	#pragma omp parallel for linear(val:2)
	for(int i = 0; i &lt; 10; i++)
	{
		printf("Thread %d sees \"val\" = %d at iteration %d.\n", omp_get_thread_num(), val, i);
	}

	printf("Value of \"val\" after the OpenMP parallel for is %d.\n", val);

	return EXIT_SUCCESS;
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sidebarblock examp">
<div class="content">
<div class="title">Reduction</div>
<div class="paragraph">
<p>The reduction clause performs a reduction on the scalar variables that appear in the list, with a specified operator.</p>
</div>
<div class="listingblock">
<div class="title">Code Reduction</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-cpp hljs" data-lang="cpp">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;omp.h&gt;

/**
 * @brief Illustrates how to do a classic reduction.
 * @details This example consists in calculating the sum of all elements of an
 * array.
 **/
int main(int argc, char* argv[])
{
	// Use 2 threads when creating OpenMP parallel regions
	omp_set_num_threads(2);

	int total = 0;
	const int ARRAY_SIZE = 10;

	int myArray[ARRAY_SIZE];
	// Initialise the array
	for(int i = 0; i &lt; ARRAY_SIZE; i++)
	{
		myArray[i] = i;
	}

	// Calculate the sum of all elements
	#pragma omp parallel for default(none) shared(myArray) firstprivate(ARRAY_SIZE) reduction(+: total)
	for(int i = 0; i &lt; ARRAY_SIZE; i++)
	{
		total += myArray[i];
	}

	printf("The sum of all array elements is equal to %d.\n", total);


	return EXIT_SUCCESS;
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sidebarblock examp">
<div class="content">
<div class="title">Schedule</div>
<div class="paragraph">
<p>Scheduling is a method in OpenMP to distribute iterations to different threads in for loop.</p>
</div>
<div class="listingblock">
<div class="title">Code Schedule</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-cpp hljs" data-lang="cpp">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;omp.h&gt;

/**
 * @brief Illustrates how to tell OpenMP which schedule to apply.
 * @details A static schedule strategy is explicitly specified, as well as the chunksize.
 **/
int main(int argc, char* argv[])
{
	// Use 2 threads when creating OpenMP parallel regions
	omp_set_num_threads(2);

	// Parallelise the for loop using the static schedule with chunks made of 2 iterations
	#pragma omp parallel for schedule(static, 2)
	for(int i = 0; i &lt; 10; i++)
	{
		printf("Thread %d processes iteration %d.\n", omp_get_thread_num(), i);
	}

	return EXIT_SUCCESS;
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sidebarblock examp">
<div class="content">
<div class="title">None</div>
<div class="paragraph">
<p>The none clause requires that each variable that is referenced in the construct, and that does not have a predetermined data-sharing attribute, must have its data-sharing attribute explicitly determined by being listed in a data-sharing attribute clause.</p>
</div>
<div class="listingblock">
<div class="title">Code None</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-cpp hljs" data-lang="cpp">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;omp.h&gt;

/**
 * @brief Illustrates the OpenMP none policy.
 * @details This example shows that the usage of the "none" default, by
 * comparing a version using implicit data-sharing clauses against that using
 * explicit data-sharing clauses. Both yield the same result, but one requires
 * the explicit usage of data-sharing clauses.
 **/
int main(int argc, char* argv[])
{
	// Use 2 OpenMP threads
	omp_set_num_threads(2);

	// Relying on the implicit default(shared)
	int implicitlyShared = 0;
	#pragma omp parallel
	{
		#pragma omp atomic
		implicitlyShared++;
	}
	printf("Value with implicit shared: %d.\n", implicitlyShared);

	// Forcing the usage of explicit data-sharing closes
	int explicitlyShared = 0;
	#pragma omp parallel default(none) shared(explicitlyShared)
	{
		#pragma omp atomic
		explicitlyShared++;
	}
	printf("Value with explicit shared: %d.\n", explicitlyShared);

	return EXIT_SUCCESS;
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sidebarblock examp">
<div class="content">
<div class="title">Task</div>
<div class="paragraph">
<p>The task pragma can be used to explicitly define a task. Use the task pragma when you want to identify a block of code to be executed in parallel with the code outside the task region. The task pragma can be useful for parallelizing irregular algorithms such as pointer chasing or recursive algorithms.</p>
</div>
<div class="listingblock">
<div class="title">Code Task</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-cpp hljs" data-lang="cpp">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;omp.h&gt;

/**
 * @brief Illustrates how to create tasks.
 * @details This application consists of a thread, in an OpenMP parallel
 * region, that spawns tasks.
 **/
int main(int argc, char* argv[])
{
	// Use 3 threads when creating OpenMP parallel regions
	omp_set_num_threads(3);

	// Create the parallel region
	#pragma omp parallel
	{
		// One thread will spawn the tasks
		#pragma omp single
		{
			// Spawn the first task
			#pragma omp task
			{
				printf("Task 1 executed by thread %d.\n", omp_get_thread_num());
			}

			// Spawn the second task
			#pragma omp task
			{
				printf("Task 2 executed by thread %d.\n", omp_get_thread_num());
			}

			// Wait for both tasks to finish
			#pragma omp taskwait
		}
	}

	return EXIT_SUCCESS;
}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Code Task Reduction</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-cpp hljs" data-lang="cpp">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;omp.h&gt;

/**
 * @brief Illustrates how to do a task reduction.
 * @details This example consists in calculating the sum of all elements of an
 * array.
 **/
int main(int argc, char* argv[])
{
	// Use 2 threads when creating OpenMP parallel regions
	omp_set_num_threads(2);

	int total = 0;
	const int ARRAY_SIZE = 10;

	int myArray[ARRAY_SIZE];

	// Initialise the array
	for(int i = 0; i &lt; ARRAY_SIZE; i++)
	{
		myArray[i] = i;
	}

	// Calculate the sum of all elements
	#pragma omp parallel
	{
		#pragma omp single
		{
			#pragma omp taskgroup task_reduction(+: total)
			{
				for(int i = 0; i &lt; ARRAY_SIZE; i++)
				{
					#pragma omp task in_reduction(+: total)
					total += myArray[i];
				}
			}
		}
	}

	printf("The sum of all array elements is %d.\n", total);


	return EXIT_SUCCESS;
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Use the taskwait pragma to specify a wait for child tasks to be completed that are generated by the current task.</p>
</div>
<div class="listingblock">
<div class="title">Code Task Wait</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-cpp hljs" data-lang="cpp">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;omp.h&gt;

/**
 * @brief Illustrates how to wait for the completion of child tasks.
 * @details This application consists of a thread, in an OpenMP parallel region,
 * that spawns tasks. It first spawns two tasks, then wait for these to complete
 * before spawning a third task. The execution flow can be visualised below:
 *
 * single construct
 *   |
 *   +------------------------------------------&gt; spawns task 1 --------+
 *   |                                                                  |
 *   |                                                            +-----+-----+
 *   +------------------------------------------&gt; spawns task 2   | A thread  |
 *   |                                                  |         | will pick |
 *   |                                            +-----+-----+   | it up and |
 *   |                                            | A thread  |   | execute   |
 *   |                                            | will pick |   | this task |
 *   |                                            | it up and |   +-----+-----+
 *   |                                            | execute   |         |
 *   |                                            | this task |         |
 *   |                                            +-----+-----+         |
 *   |                                                  |               |
 *   +--&gt; waits for tasks 1 and 2 to complete      |////////////////////////|
 *   |
 *   +--&gt; spawns task 3 ----------------------------------------------+
 *   |                                                                |
 *   |                                                          +-----+-----+
 *   |                                                          | A thread  |
 *   |                                                          | will pick |
 *   |                                                          | it up and |
 *   |                                                          | execute   |
 *   |                                                          | this task |
 *   |                                                          +-----+-----+
 *   |                                                                |
 *   +--&gt; implicit barrier at the end of the single construct |///////////////|
 **/
int main(int argc, char* argv[])
{
    // Use 3 threads when creating OpenMP parallel regions
    omp_set_num_threads(3);

    // Create the parallel region
    #pragma omp parallel
    {
        #pragma omp single
        {
            // Spawn the first task
            #pragma omp task
            {
                printf("Task 1 executed by thread %d.\n", omp_get_thread_num());
            }

            // Spawn the second task
            #pragma omp task
            {
                printf("Task 2 executed by thread %d.\n", omp_get_thread_num());
            }

            // Wait for the two tasks above to complete before moving to the third one
            #pragma omp taskwait

            // One thread indicates that the synchronisation is finished
            printf("The taskwait construct completed, which means tasks 1 and 2 are complete. We can now move to task 3.\n");

            // Spawn the third task
            #pragma omp task
            {
                printf("Task 3 executed by thread %d.\n", omp_get_thread_num());
            }

            // The implicit barrier at the end of the single construct will wait for tasks to finish
        }
    }

    return EXIT_SUCCESS;
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>&#8230;&#8203;</p>
</div>
</article>
  </div>
</main>
</div>
<footer class="footer" style="border-top: 2px solid #e9e9e9; background-color: #fafafa; padding-bottom: 2em; padding-top: 2em;">
    <div class="container" style="display: flex; flex-direction: column; align-items: center; gap: 0.5em;">
        <div>
            <a href="https://www.cemosis.fr">
                <img src="../_/img/cemosis-logo.svg" alt="Cemosis logo" height="50">
            </a>
        </div>
        <span style="font-size: 0.8rem; color: #9e9e9e">© 2023 <a href="https://www.cemosis.fr" style="text-decoration: underline;">Cemosis</a>, Université de Strasbourg</span>
    </div>
</footer>
<script id="site-script" src="../_/js/site.js" data-ui-root-path="../_"></script>


<script async src="../_/js/vendor/fontawesome-icon-defs.js"></script>
<script async src="../_/js/vendor/fontawesome.js"></script>
<script async src="../_/js/vendor/highlight.js"></script>


<script type="text/javascript">
function toggleFullScreen() {
   var doc = window.document;
   var docEl = doc.documentElement;

   var requestFullScreen = docEl.requestFullscreen || docEl.mozRequestFullScreen || docEl.webkitRequestFullScreen || docEl.msRequestFullscreen;
   var cancelFullScreen = doc.exitFullscreen || doc.mozCancelFullScreen || doc.webkitExitFullscreen || doc.msExitFullscreen;

   if(!doc.fullscreenElement && !doc.mozFullScreenElement && !doc.webkitFullscreenElement && !doc.msFullscreenElement) {
       requestFullScreen.call(docEl);
   }
   else {
       cancelFullScreen.call(doc);
   }
}
</script>
  </body>
</html>
